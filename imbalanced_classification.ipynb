{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imbalanced_classification",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvCIvh3nx84g",
        "colab_type": "text"
      },
      "source": [
        "![임도형 커멘트](https://github.com/dhrim/keras_example_seminia_2020/raw/master/comment.png)\n",
        "\n",
        "# 개요\n",
        "\n",
        "- 원 본 : https://keras.io/examples/structured_data/imbalanced_classification/\n",
        "\n",
        "- 작업 : classification\n",
        "- 데이터 : 속성 데이터. 테이블 데이터. https://www.kaggle.com/mlg-ulb/creditcardfraud/\n",
        "- 적용 모델 : DNN\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "# 데이터\n",
        "\n",
        "신용카드 데이터. 속성들만 있는\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "# 모델\n",
        "\n",
        "Nothing Special\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "# class_weight에 의한 데이터 비균등 처리\n",
        "\n",
        "model.fit() 호출 시에 class_weight를 주면 loss에 해당 가중치를 주어 계산한다. focal loss가 이런 개념인데, Keras에서 class_weight로 구현해 놓았다.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1NtltRP6QzI",
        "colab_type": "text"
      },
      "source": [
        "# 태그\n",
        "\n",
        "```\n",
        "#structued_data\n",
        "#attribute_data\n",
        "#class_weight\n",
        "#np.bincount()\n",
        "#keras_metrics\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i7dSnkj2EiS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "b9a09231-4115-4f89-f34d-8d94240bd07c"
      },
      "source": [
        "%%shell\n",
        "wget https://github.com/dhrim/keras_example_seminia_2020/raw/master/creditcard.csv.zip\n",
        "unzip creditcard.csv.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-24 06:43:20--  https://github.com/dhrim/keras_example_seminia_2020/raw/master/creditcard.csv.zip\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/dhrim/keras_example_seminia_2020/master/creditcard.csv.zip [following]\n",
            "--2020-09-24 06:43:21--  https://raw.githubusercontent.com/dhrim/keras_example_seminia_2020/master/creditcard.csv.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 69155672 (66M) [application/zip]\n",
            "Saving to: ‘creditcard.csv.zip’\n",
            "\n",
            "creditcard.csv.zip  100%[===================>]  65.95M  76.3MB/s    in 0.9s    \n",
            "\n",
            "2020-09-24 06:43:21 (76.3 MB/s) - ‘creditcard.csv.zip’ saved [69155672/69155672]\n",
            "\n",
            "Archive:  creditcard.csv.zip\n",
            "  inflating: creditcard.csv          \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AEEYWTVhwY3Q"
      },
      "source": [
        "# Imbalanced classification: credit card fraud detection\n",
        "\n",
        "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2019/05/28<br>\n",
        "**Last modified:** 2020/04/17<br>\n",
        "**Description:** Demonstration of how to handle highly imbalanced classification problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1OfU5UOVwY3S"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This example looks at the\n",
        "[Kaggle Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud/)\n",
        "dataset to demonstrate how\n",
        "to train a classification model on data with highly imbalanced classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lwl6lbGAwY3T"
      },
      "source": [
        "## First, vectorize the CSV data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cum9mK6zwY3U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "4da71331-0a43-495a-81f3-f6ad0ac454ed"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "# Get the real data from https://www.kaggle.com/mlg-ulb/creditcardfraud/\n",
        "# fname = \"/Users/fchollet/Downloads/creditcard.csv\"\n",
        "fname = \"creditcard.csv\"\n",
        "\n",
        "all_features = []\n",
        "all_targets = []\n",
        "with open(fname) as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i == 0:\n",
        "            print(\"HEADER:\", line.strip())\n",
        "            continue  # Skip header\n",
        "        fields = line.strip().split(\",\")\n",
        "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
        "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
        "        if i == 1:\n",
        "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
        "\n",
        "features = np.array(all_features, dtype=\"float32\")\n",
        "targets = np.array(all_targets, dtype=\"uint8\")\n",
        "print(\"features.shape:\", features.shape)\n",
        "print(\"targets.shape:\", targets.shape)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
            "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
            "features.shape: (284807, 30)\n",
            "targets.shape: (284807, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pbnzLa9KwY3Y"
      },
      "source": [
        "## Prepare a validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oH2f4Xj8wY3Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "009e4a93-d3b2-4775-c2cc-0bacb5fefd1e"
      },
      "source": [
        "num_val_samples = int(len(features) * 0.2)\n",
        "train_features = features[:-num_val_samples]\n",
        "train_targets = targets[:-num_val_samples]\n",
        "val_features = features[-num_val_samples:]\n",
        "val_targets = targets[-num_val_samples:]\n",
        "\n",
        "print(\"Number of training samples:\", len(train_features))\n",
        "print(\"Number of validation samples:\", len(val_features))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples: 227846\n",
            "Number of validation samples: 56961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XZiyh6DdwY3d"
      },
      "source": [
        "## Analyze class imbalance in the targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhGpk7ia3bKL",
        "colab_type": "text"
      },
      "source": [
        "![임도형 커멘트](https://github.com/dhrim/keras_example_seminia_2020/raw/master/comment.png)\n",
        "\n",
        "카테고리 0은 22749개, 카테고리 1은 417개. 82:18의 비율이다.\n",
        "\n",
        "np.bincount()로 숫자 빈도수를 셀수 있다.\n",
        "\n",
        "학습에 사용할 class weight를 1/82, 1/18로 한다. 결국 18:82가 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qUCYCiAtwY3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8b5e6580-f670-410f-8bee-084a9d0112d4"
      },
      "source": [
        "counts = np.bincount(train_targets[:, 0])\n",
        "print(counts)\n",
        "print(\n",
        "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
        "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
        "    )\n",
        ")\n",
        "\n",
        "weight_for_0 = 1.0 / counts[0]\n",
        "weight_for_1 = 1.0 / counts[1]\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[227429    417]\n",
            "Number of positive samples in training data: 417 (0.18% of total)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "avgYMmIKwY3h"
      },
      "source": [
        "## Normalize the data using training set statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-yZ9OhzSwY3i",
        "colab": {}
      },
      "source": [
        "mean = np.mean(train_features, axis=0)\n",
        "train_features -= mean\n",
        "val_features -= mean\n",
        "std = np.std(train_features, axis=0)\n",
        "train_features /= std\n",
        "val_features /= std\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iV5zzsNqwY3m"
      },
      "source": [
        "## Build a binary classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vdXCXGDzwY3m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "485f0933-65cf-402d-e2d1-d89ab50cc3ea"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Dense(256, activation=\"relu\", input_shape=(train_features.shape[-1],)),\n",
        "        keras.layers.Dense(256, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(256, activation=\"relu\"),\n",
        "        keras.layers.Dropout(0.3),\n",
        "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "model.summary()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 256)               7936      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 139,777\n",
            "Trainable params: 139,777\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U4q4CIoVwY3q"
      },
      "source": [
        "## Train the model with `class_weight` argument"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nFIhvYjLwY3q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b1d73d2f-6667-4932-fc6f-57e959b6070e"
      },
      "source": [
        "metrics = [\n",
        "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "    keras.metrics.FalsePositives(name=\"fp\"),\n",
        "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "    keras.metrics.TruePositives(name=\"tp\"),\n",
        "    keras.metrics.Precision(name=\"precision\"),\n",
        "    keras.metrics.Recall(name=\"recall\"),\n",
        "]\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
        ")\n",
        "\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "model.fit(\n",
        "    train_features,\n",
        "    train_targets,\n",
        "    batch_size=2048,\n",
        "    epochs=30,\n",
        "    verbose=2,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=(val_features, val_targets),\n",
        "    class_weight=class_weight,\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "112/112 - 6s - loss: 1.5320e-06 - fn: 58.0000 - fp: 742.0000 - tn: 226687.0000 - tp: 359.0000 - precision: 0.3261 - recall: 0.8609 - val_loss: 0.0307 - val_fn: 14.0000 - val_fp: 145.0000 - val_tn: 56741.0000 - val_tp: 61.0000 - val_precision: 0.2961 - val_recall: 0.8133\n",
            "Epoch 2/30\n",
            "112/112 - 5s - loss: 4.5041e-07 - fn: 17.0000 - fp: 1155.0000 - tn: 226274.0000 - tp: 400.0000 - precision: 0.2572 - recall: 0.9592 - val_loss: 0.0302 - val_fn: 14.0000 - val_fp: 65.0000 - val_tn: 56821.0000 - val_tp: 61.0000 - val_precision: 0.4841 - val_recall: 0.8133\n",
            "Epoch 3/30\n",
            "112/112 - 5s - loss: 2.6920e-07 - fn: 13.0000 - fp: 826.0000 - tn: 226603.0000 - tp: 404.0000 - precision: 0.3285 - recall: 0.9688 - val_loss: 0.0313 - val_fn: 17.0000 - val_fp: 62.0000 - val_tn: 56824.0000 - val_tp: 58.0000 - val_precision: 0.4833 - val_recall: 0.7733\n",
            "Epoch 4/30\n",
            "112/112 - 5s - loss: 2.2644e-07 - fn: 9.0000 - fp: 598.0000 - tn: 226831.0000 - tp: 408.0000 - precision: 0.4056 - recall: 0.9784 - val_loss: 0.0342 - val_fn: 17.0000 - val_fp: 66.0000 - val_tn: 56820.0000 - val_tp: 58.0000 - val_precision: 0.4677 - val_recall: 0.7733\n",
            "Epoch 5/30\n",
            "112/112 - 5s - loss: 2.7622e-07 - fn: 9.0000 - fp: 1342.0000 - tn: 226087.0000 - tp: 408.0000 - precision: 0.2331 - recall: 0.9784 - val_loss: 0.0337 - val_fn: 15.0000 - val_fp: 61.0000 - val_tn: 56825.0000 - val_tp: 60.0000 - val_precision: 0.4959 - val_recall: 0.8000\n",
            "Epoch 6/30\n",
            "112/112 - 5s - loss: 1.8766e-07 - fn: 5.0000 - fp: 903.0000 - tn: 226526.0000 - tp: 412.0000 - precision: 0.3133 - recall: 0.9880 - val_loss: 0.0386 - val_fn: 17.0000 - val_fp: 48.0000 - val_tn: 56838.0000 - val_tp: 58.0000 - val_precision: 0.5472 - val_recall: 0.7733\n",
            "Epoch 7/30\n",
            "112/112 - 5s - loss: 1.6693e-07 - fn: 4.0000 - fp: 711.0000 - tn: 226718.0000 - tp: 413.0000 - precision: 0.3674 - recall: 0.9904 - val_loss: 0.0396 - val_fn: 17.0000 - val_fp: 37.0000 - val_tn: 56849.0000 - val_tp: 58.0000 - val_precision: 0.6105 - val_recall: 0.7733\n",
            "Epoch 8/30\n",
            "112/112 - 5s - loss: 1.2143e-07 - fn: 1.0000 - fp: 758.0000 - tn: 226671.0000 - tp: 416.0000 - precision: 0.3543 - recall: 0.9976 - val_loss: 0.0452 - val_fn: 18.0000 - val_fp: 63.0000 - val_tn: 56823.0000 - val_tp: 57.0000 - val_precision: 0.4750 - val_recall: 0.7600\n",
            "Epoch 9/30\n",
            "112/112 - 5s - loss: 1.7112e-07 - fn: 6.0000 - fp: 771.0000 - tn: 226658.0000 - tp: 411.0000 - precision: 0.3477 - recall: 0.9856 - val_loss: 0.0420 - val_fn: 18.0000 - val_fp: 46.0000 - val_tn: 56840.0000 - val_tp: 57.0000 - val_precision: 0.5534 - val_recall: 0.7600\n",
            "Epoch 10/30\n",
            "112/112 - 5s - loss: 3.6617e-07 - fn: 5.0000 - fp: 1648.0000 - tn: 225781.0000 - tp: 412.0000 - precision: 0.2000 - recall: 0.9880 - val_loss: 0.0418 - val_fn: 18.0000 - val_fp: 48.0000 - val_tn: 56838.0000 - val_tp: 57.0000 - val_precision: 0.5429 - val_recall: 0.7600\n",
            "Epoch 11/30\n",
            "112/112 - 5s - loss: 2.4387e-07 - fn: 3.0000 - fp: 938.0000 - tn: 226491.0000 - tp: 414.0000 - precision: 0.3062 - recall: 0.9928 - val_loss: 0.0393 - val_fn: 17.0000 - val_fp: 68.0000 - val_tn: 56818.0000 - val_tp: 58.0000 - val_precision: 0.4603 - val_recall: 0.7733\n",
            "Epoch 12/30\n",
            "112/112 - 5s - loss: 1.6315e-07 - fn: 4.0000 - fp: 716.0000 - tn: 226713.0000 - tp: 413.0000 - precision: 0.3658 - recall: 0.9904 - val_loss: 0.0420 - val_fn: 14.0000 - val_fp: 85.0000 - val_tn: 56801.0000 - val_tp: 61.0000 - val_precision: 0.4178 - val_recall: 0.8133\n",
            "Epoch 13/30\n",
            "112/112 - 6s - loss: 1.4296e-07 - fn: 3.0000 - fp: 830.0000 - tn: 226599.0000 - tp: 414.0000 - precision: 0.3328 - recall: 0.9928 - val_loss: 0.0447 - val_fn: 17.0000 - val_fp: 51.0000 - val_tn: 56835.0000 - val_tp: 58.0000 - val_precision: 0.5321 - val_recall: 0.7733\n",
            "Epoch 14/30\n",
            "112/112 - 6s - loss: 1.8442e-07 - fn: 4.0000 - fp: 1053.0000 - tn: 226376.0000 - tp: 413.0000 - precision: 0.2817 - recall: 0.9904 - val_loss: 0.0518 - val_fn: 11.0000 - val_fp: 199.0000 - val_tn: 56687.0000 - val_tp: 64.0000 - val_precision: 0.2433 - val_recall: 0.8533\n",
            "Epoch 15/30\n",
            "112/112 - 6s - loss: 1.4698e-07 - fn: 1.0000 - fp: 1079.0000 - tn: 226350.0000 - tp: 416.0000 - precision: 0.2783 - recall: 0.9976 - val_loss: 0.0513 - val_fn: 13.0000 - val_fp: 155.0000 - val_tn: 56731.0000 - val_tp: 62.0000 - val_precision: 0.2857 - val_recall: 0.8267\n",
            "Epoch 16/30\n",
            "112/112 - 5s - loss: 6.9704e-08 - fn: 0.0000e+00 - fp: 952.0000 - tn: 226477.0000 - tp: 417.0000 - precision: 0.3046 - recall: 1.0000 - val_loss: 0.0493 - val_fn: 14.0000 - val_fp: 135.0000 - val_tn: 56751.0000 - val_tp: 61.0000 - val_precision: 0.3112 - val_recall: 0.8133\n",
            "Epoch 17/30\n",
            "112/112 - 5s - loss: 9.8102e-08 - fn: 0.0000e+00 - fp: 819.0000 - tn: 226610.0000 - tp: 417.0000 - precision: 0.3374 - recall: 1.0000 - val_loss: 0.0520 - val_fn: 14.0000 - val_fp: 106.0000 - val_tn: 56780.0000 - val_tp: 61.0000 - val_precision: 0.3653 - val_recall: 0.8133\n",
            "Epoch 18/30\n",
            "112/112 - 5s - loss: 8.8570e-08 - fn: 2.0000 - fp: 703.0000 - tn: 226726.0000 - tp: 415.0000 - precision: 0.3712 - recall: 0.9952 - val_loss: 0.0529 - val_fn: 13.0000 - val_fp: 104.0000 - val_tn: 56782.0000 - val_tp: 62.0000 - val_precision: 0.3735 - val_recall: 0.8267\n",
            "Epoch 19/30\n",
            "112/112 - 5s - loss: 1.0272e-07 - fn: 1.0000 - fp: 894.0000 - tn: 226535.0000 - tp: 416.0000 - precision: 0.3176 - recall: 0.9976 - val_loss: 0.0512 - val_fn: 13.0000 - val_fp: 88.0000 - val_tn: 56798.0000 - val_tp: 62.0000 - val_precision: 0.4133 - val_recall: 0.8267\n",
            "Epoch 20/30\n",
            "112/112 - 5s - loss: 1.0489e-07 - fn: 0.0000e+00 - fp: 732.0000 - tn: 226697.0000 - tp: 417.0000 - precision: 0.3629 - recall: 1.0000 - val_loss: 0.0586 - val_fn: 13.0000 - val_fp: 95.0000 - val_tn: 56791.0000 - val_tp: 62.0000 - val_precision: 0.3949 - val_recall: 0.8267\n",
            "Epoch 21/30\n",
            "112/112 - 5s - loss: 3.1421e-07 - fn: 2.0000 - fp: 2123.0000 - tn: 225306.0000 - tp: 415.0000 - precision: 0.1635 - recall: 0.9952 - val_loss: 0.0540 - val_fn: 16.0000 - val_fp: 82.0000 - val_tn: 56804.0000 - val_tp: 59.0000 - val_precision: 0.4184 - val_recall: 0.7867\n",
            "Epoch 22/30\n",
            "112/112 - 5s - loss: 1.9887e-07 - fn: 2.0000 - fp: 1312.0000 - tn: 226117.0000 - tp: 415.0000 - precision: 0.2403 - recall: 0.9952 - val_loss: 0.0533 - val_fn: 15.0000 - val_fp: 76.0000 - val_tn: 56810.0000 - val_tp: 60.0000 - val_precision: 0.4412 - val_recall: 0.8000\n",
            "Epoch 23/30\n",
            "112/112 - 5s - loss: 8.5804e-07 - fn: 3.0000 - fp: 3890.0000 - tn: 223539.0000 - tp: 414.0000 - precision: 0.0962 - recall: 0.9928 - val_loss: 0.0508 - val_fn: 15.0000 - val_fp: 304.0000 - val_tn: 56582.0000 - val_tp: 60.0000 - val_precision: 0.1648 - val_recall: 0.8000\n",
            "Epoch 24/30\n",
            "112/112 - 5s - loss: 5.4160e-07 - fn: 2.0000 - fp: 2147.0000 - tn: 225282.0000 - tp: 415.0000 - precision: 0.1620 - recall: 0.9952 - val_loss: 0.0461 - val_fn: 12.0000 - val_fp: 240.0000 - val_tn: 56646.0000 - val_tp: 63.0000 - val_precision: 0.2079 - val_recall: 0.8400\n",
            "Epoch 25/30\n",
            "112/112 - 5s - loss: 2.7215e-07 - fn: 0.0000e+00 - fp: 1558.0000 - tn: 225871.0000 - tp: 417.0000 - precision: 0.2111 - recall: 1.0000 - val_loss: 0.0477 - val_fn: 12.0000 - val_fp: 215.0000 - val_tn: 56671.0000 - val_tp: 63.0000 - val_precision: 0.2266 - val_recall: 0.8400\n",
            "Epoch 26/30\n",
            "112/112 - 5s - loss: 2.0563e-07 - fn: 0.0000e+00 - fp: 1342.0000 - tn: 226087.0000 - tp: 417.0000 - precision: 0.2371 - recall: 1.0000 - val_loss: 0.0586 - val_fn: 12.0000 - val_fp: 139.0000 - val_tn: 56747.0000 - val_tp: 63.0000 - val_precision: 0.3119 - val_recall: 0.8400\n",
            "Epoch 27/30\n",
            "112/112 - 5s - loss: 2.0252e-07 - fn: 1.0000 - fp: 949.0000 - tn: 226480.0000 - tp: 416.0000 - precision: 0.3048 - recall: 0.9976 - val_loss: 0.0503 - val_fn: 13.0000 - val_fp: 192.0000 - val_tn: 56694.0000 - val_tp: 62.0000 - val_precision: 0.2441 - val_recall: 0.8267\n",
            "Epoch 28/30\n",
            "112/112 - 5s - loss: 1.7705e-07 - fn: 2.0000 - fp: 1115.0000 - tn: 226314.0000 - tp: 415.0000 - precision: 0.2712 - recall: 0.9952 - val_loss: 0.0452 - val_fn: 13.0000 - val_fp: 170.0000 - val_tn: 56716.0000 - val_tp: 62.0000 - val_precision: 0.2672 - val_recall: 0.8267\n",
            "Epoch 29/30\n",
            "112/112 - 5s - loss: 7.6728e-07 - fn: 2.0000 - fp: 2817.0000 - tn: 224612.0000 - tp: 415.0000 - precision: 0.1284 - recall: 0.9952 - val_loss: 0.0827 - val_fn: 10.0000 - val_fp: 1010.0000 - val_tn: 55876.0000 - val_tp: 65.0000 - val_precision: 0.0605 - val_recall: 0.8667\n",
            "Epoch 30/30\n",
            "112/112 - 5s - loss: 4.8318e-07 - fn: 1.0000 - fp: 9514.0000 - tn: 217915.0000 - tp: 416.0000 - precision: 0.0419 - recall: 0.9976 - val_loss: 0.0723 - val_fn: 12.0000 - val_fp: 459.0000 - val_tn: 56427.0000 - val_tp: 63.0000 - val_precision: 0.1207 - val_recall: 0.8400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd55a72b0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5K2RDVk5NFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouD_bImY2trn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "9165023b-2df0-48e3-9127-1e947897b0b2"
      },
      "source": [
        "with_weight_class_result = model.evaluate(val_features, val_targets)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1781/1781 [==============================] - 2s 1ms/step - loss: 0.0723 - fn: 12.0000 - fp: 459.0000 - tn: 56427.0000 - tp: 63.0000 - precision: 0.1207 - recall: 0.8400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-MksUT851-9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b0df57e-976c-4890-c938-bba61fc05b03"
      },
      "source": [
        "metrics = [\n",
        "    keras.metrics.FalseNegatives(name=\"fn\"),\n",
        "    keras.metrics.FalsePositives(name=\"fp\"),\n",
        "    keras.metrics.TrueNegatives(name=\"tn\"),\n",
        "    keras.metrics.TruePositives(name=\"tp\"),\n",
        "    keras.metrics.Precision(name=\"precision\"),\n",
        "    keras.metrics.Recall(name=\"recall\"),\n",
        "]\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-2), loss=\"binary_crossentropy\", metrics=metrics\n",
        ")\n",
        "\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "model.fit(\n",
        "    train_features,\n",
        "    train_targets,\n",
        "    batch_size=2048,\n",
        "    epochs=30,\n",
        "    verbose=2,\n",
        "    callbacks=callbacks,\n",
        "    validation_data=(val_features, val_targets),\n",
        "    # class_weight=class_weight, # COMMENT OUT\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "112/112 - 6s - loss: 0.0057 - fn: 137.0000 - fp: 100.0000 - tn: 227329.0000 - tp: 280.0000 - precision: 0.7368 - recall: 0.6715 - val_loss: 0.0049 - val_fn: 19.0000 - val_fp: 6.0000 - val_tn: 56880.0000 - val_tp: 56.0000 - val_precision: 0.9032 - val_recall: 0.7467\n",
            "Epoch 2/30\n",
            "112/112 - 5s - loss: 0.0031 - fn: 105.0000 - fp: 68.0000 - tn: 227361.0000 - tp: 312.0000 - precision: 0.8211 - recall: 0.7482 - val_loss: 0.0057 - val_fn: 22.0000 - val_fp: 2.0000 - val_tn: 56884.0000 - val_tp: 53.0000 - val_precision: 0.9636 - val_recall: 0.7067\n",
            "Epoch 3/30\n",
            "112/112 - 5s - loss: 0.0032 - fn: 133.0000 - fp: 55.0000 - tn: 227374.0000 - tp: 284.0000 - precision: 0.8378 - recall: 0.6811 - val_loss: 0.0049 - val_fn: 20.0000 - val_fp: 6.0000 - val_tn: 56880.0000 - val_tp: 55.0000 - val_precision: 0.9016 - val_recall: 0.7333\n",
            "Epoch 4/30\n",
            "112/112 - 6s - loss: 0.0026 - fn: 117.0000 - fp: 54.0000 - tn: 227375.0000 - tp: 300.0000 - precision: 0.8475 - recall: 0.7194 - val_loss: 0.0110 - val_fn: 19.0000 - val_fp: 7.0000 - val_tn: 56879.0000 - val_tp: 56.0000 - val_precision: 0.8889 - val_recall: 0.7467\n",
            "Epoch 5/30\n",
            "112/112 - 6s - loss: 0.0033 - fn: 126.0000 - fp: 66.0000 - tn: 227363.0000 - tp: 291.0000 - precision: 0.8151 - recall: 0.6978 - val_loss: 0.0065 - val_fn: 19.0000 - val_fp: 6.0000 - val_tn: 56880.0000 - val_tp: 56.0000 - val_precision: 0.9032 - val_recall: 0.7467\n",
            "Epoch 6/30\n",
            "112/112 - 5s - loss: 0.0022 - fn: 102.0000 - fp: 53.0000 - tn: 227376.0000 - tp: 315.0000 - precision: 0.8560 - recall: 0.7554 - val_loss: 0.0055 - val_fn: 19.0000 - val_fp: 8.0000 - val_tn: 56878.0000 - val_tp: 56.0000 - val_precision: 0.8750 - val_recall: 0.7467\n",
            "Epoch 7/30\n",
            "112/112 - 5s - loss: 0.0024 - fn: 126.0000 - fp: 46.0000 - tn: 227383.0000 - tp: 291.0000 - precision: 0.8635 - recall: 0.6978 - val_loss: 0.0058 - val_fn: 22.0000 - val_fp: 3.0000 - val_tn: 56883.0000 - val_tp: 53.0000 - val_precision: 0.9464 - val_recall: 0.7067\n",
            "Epoch 8/30\n",
            "112/112 - 5s - loss: 0.0026 - fn: 105.0000 - fp: 56.0000 - tn: 227373.0000 - tp: 312.0000 - precision: 0.8478 - recall: 0.7482 - val_loss: 0.0130 - val_fn: 19.0000 - val_fp: 4.0000 - val_tn: 56882.0000 - val_tp: 56.0000 - val_precision: 0.9333 - val_recall: 0.7467\n",
            "Epoch 9/30\n",
            "112/112 - 5s - loss: 0.0030 - fn: 112.0000 - fp: 43.0000 - tn: 227386.0000 - tp: 305.0000 - precision: 0.8764 - recall: 0.7314 - val_loss: 0.0089 - val_fn: 32.0000 - val_fp: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 43.0000 - val_precision: 1.0000 - val_recall: 0.5733\n",
            "Epoch 10/30\n",
            "112/112 - 5s - loss: 0.0030 - fn: 138.0000 - fp: 35.0000 - tn: 227394.0000 - tp: 279.0000 - precision: 0.8885 - recall: 0.6691 - val_loss: 0.0141 - val_fn: 20.0000 - val_fp: 5.0000 - val_tn: 56881.0000 - val_tp: 55.0000 - val_precision: 0.9167 - val_recall: 0.7333\n",
            "Epoch 11/30\n",
            "112/112 - 5s - loss: 0.0030 - fn: 120.0000 - fp: 52.0000 - tn: 227377.0000 - tp: 297.0000 - precision: 0.8510 - recall: 0.7122 - val_loss: 0.0073 - val_fn: 20.0000 - val_fp: 5.0000 - val_tn: 56881.0000 - val_tp: 55.0000 - val_precision: 0.9167 - val_recall: 0.7333\n",
            "Epoch 12/30\n",
            "112/112 - 5s - loss: 0.0036 - fn: 107.0000 - fp: 45.0000 - tn: 227384.0000 - tp: 310.0000 - precision: 0.8732 - recall: 0.7434 - val_loss: 0.0056 - val_fn: 20.0000 - val_fp: 11.0000 - val_tn: 56875.0000 - val_tp: 55.0000 - val_precision: 0.8333 - val_recall: 0.7333\n",
            "Epoch 13/30\n",
            "112/112 - 6s - loss: 0.0029 - fn: 124.0000 - fp: 31.0000 - tn: 227398.0000 - tp: 293.0000 - precision: 0.9043 - recall: 0.7026 - val_loss: 0.0051 - val_fn: 22.0000 - val_fp: 7.0000 - val_tn: 56879.0000 - val_tp: 53.0000 - val_precision: 0.8833 - val_recall: 0.7067\n",
            "Epoch 14/30\n",
            "112/112 - 5s - loss: 0.0023 - fn: 114.0000 - fp: 32.0000 - tn: 227397.0000 - tp: 303.0000 - precision: 0.9045 - recall: 0.7266 - val_loss: 0.0141 - val_fn: 33.0000 - val_fp: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 42.0000 - val_precision: 1.0000 - val_recall: 0.5600\n",
            "Epoch 15/30\n",
            "112/112 - 5s - loss: 0.0019 - fn: 122.0000 - fp: 25.0000 - tn: 227404.0000 - tp: 295.0000 - precision: 0.9219 - recall: 0.7074 - val_loss: 0.0085 - val_fn: 26.0000 - val_fp: 4.0000 - val_tn: 56882.0000 - val_tp: 49.0000 - val_precision: 0.9245 - val_recall: 0.6533\n",
            "Epoch 16/30\n",
            "112/112 - 5s - loss: 0.0021 - fn: 131.0000 - fp: 33.0000 - tn: 227396.0000 - tp: 286.0000 - precision: 0.8966 - recall: 0.6859 - val_loss: 0.0101 - val_fn: 52.0000 - val_fp: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 23.0000 - val_precision: 1.0000 - val_recall: 0.3067\n",
            "Epoch 17/30\n",
            "112/112 - 5s - loss: 0.0018 - fn: 114.0000 - fp: 29.0000 - tn: 227400.0000 - tp: 303.0000 - precision: 0.9127 - recall: 0.7266 - val_loss: 0.0094 - val_fn: 32.0000 - val_fp: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 43.0000 - val_precision: 1.0000 - val_recall: 0.5733\n",
            "Epoch 18/30\n",
            "112/112 - 5s - loss: 0.0043 - fn: 117.0000 - fp: 45.0000 - tn: 227384.0000 - tp: 300.0000 - precision: 0.8696 - recall: 0.7194 - val_loss: 0.0124 - val_fn: 39.0000 - val_fp: 2.0000 - val_tn: 56884.0000 - val_tp: 36.0000 - val_precision: 0.9474 - val_recall: 0.4800\n",
            "Epoch 19/30\n",
            "112/112 - 5s - loss: 0.0028 - fn: 151.0000 - fp: 26.0000 - tn: 227403.0000 - tp: 266.0000 - precision: 0.9110 - recall: 0.6379 - val_loss: 0.0092 - val_fn: 20.0000 - val_fp: 4.0000 - val_tn: 56882.0000 - val_tp: 55.0000 - val_precision: 0.9322 - val_recall: 0.7333\n",
            "Epoch 20/30\n",
            "112/112 - 5s - loss: 0.0026 - fn: 150.0000 - fp: 34.0000 - tn: 227395.0000 - tp: 267.0000 - precision: 0.8870 - recall: 0.6403 - val_loss: 0.0128 - val_fn: 27.0000 - val_fp: 1.0000 - val_tn: 56885.0000 - val_tp: 48.0000 - val_precision: 0.9796 - val_recall: 0.6400\n",
            "Epoch 21/30\n",
            "112/112 - 5s - loss: 0.0022 - fn: 130.0000 - fp: 26.0000 - tn: 227403.0000 - tp: 287.0000 - precision: 0.9169 - recall: 0.6882 - val_loss: 0.0164 - val_fn: 19.0000 - val_fp: 2.0000 - val_tn: 56884.0000 - val_tp: 56.0000 - val_precision: 0.9655 - val_recall: 0.7467\n",
            "Epoch 22/30\n",
            "112/112 - 5s - loss: 0.0026 - fn: 111.0000 - fp: 29.0000 - tn: 227400.0000 - tp: 306.0000 - precision: 0.9134 - recall: 0.7338 - val_loss: 0.0231 - val_fn: 22.0000 - val_fp: 2.0000 - val_tn: 56884.0000 - val_tp: 53.0000 - val_precision: 0.9636 - val_recall: 0.7067\n",
            "Epoch 23/30\n",
            "112/112 - 6s - loss: 0.0022 - fn: 108.0000 - fp: 28.0000 - tn: 227401.0000 - tp: 309.0000 - precision: 0.9169 - recall: 0.7410 - val_loss: 0.0280 - val_fn: 26.0000 - val_fp: 0.0000e+00 - val_tn: 56886.0000 - val_tp: 49.0000 - val_precision: 1.0000 - val_recall: 0.6533\n",
            "Epoch 24/30\n",
            "112/112 - 5s - loss: 0.0020 - fn: 110.0000 - fp: 27.0000 - tn: 227402.0000 - tp: 307.0000 - precision: 0.9192 - recall: 0.7362 - val_loss: 0.0322 - val_fn: 19.0000 - val_fp: 3.0000 - val_tn: 56883.0000 - val_tp: 56.0000 - val_precision: 0.9492 - val_recall: 0.7467\n",
            "Epoch 25/30\n",
            "112/112 - 5s - loss: 0.0015 - fn: 96.0000 - fp: 22.0000 - tn: 227407.0000 - tp: 321.0000 - precision: 0.9359 - recall: 0.7698 - val_loss: 0.0261 - val_fn: 21.0000 - val_fp: 4.0000 - val_tn: 56882.0000 - val_tp: 54.0000 - val_precision: 0.9310 - val_recall: 0.7200\n",
            "Epoch 26/30\n",
            "112/112 - 5s - loss: 0.0010 - fn: 77.0000 - fp: 13.0000 - tn: 227416.0000 - tp: 340.0000 - precision: 0.9632 - recall: 0.8153 - val_loss: 0.0333 - val_fn: 20.0000 - val_fp: 5.0000 - val_tn: 56881.0000 - val_tp: 55.0000 - val_precision: 0.9167 - val_recall: 0.7333\n",
            "Epoch 27/30\n",
            "112/112 - 5s - loss: 0.0014 - fn: 82.0000 - fp: 30.0000 - tn: 227399.0000 - tp: 335.0000 - precision: 0.9178 - recall: 0.8034 - val_loss: 0.0547 - val_fn: 28.0000 - val_fp: 5.0000 - val_tn: 56881.0000 - val_tp: 47.0000 - val_precision: 0.9038 - val_recall: 0.6267\n",
            "Epoch 28/30\n",
            "112/112 - 5s - loss: 0.0071 - fn: 127.0000 - fp: 74.0000 - tn: 227355.0000 - tp: 290.0000 - precision: 0.7967 - recall: 0.6954 - val_loss: 0.0338 - val_fn: 23.0000 - val_fp: 6.0000 - val_tn: 56880.0000 - val_tp: 52.0000 - val_precision: 0.8966 - val_recall: 0.6933\n",
            "Epoch 29/30\n",
            "112/112 - 5s - loss: 0.0054 - fn: 153.0000 - fp: 38.0000 - tn: 227391.0000 - tp: 264.0000 - precision: 0.8742 - recall: 0.6331 - val_loss: 0.0209 - val_fn: 23.0000 - val_fp: 1.0000 - val_tn: 56885.0000 - val_tp: 52.0000 - val_precision: 0.9811 - val_recall: 0.6933\n",
            "Epoch 30/30\n",
            "112/112 - 5s - loss: 0.0029 - fn: 145.0000 - fp: 15.0000 - tn: 227414.0000 - tp: 272.0000 - precision: 0.9477 - recall: 0.6523 - val_loss: 0.0227 - val_fn: 28.0000 - val_fp: 2.0000 - val_tn: 56884.0000 - val_tp: 47.0000 - val_precision: 0.9592 - val_recall: 0.6267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd55b5cdfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAkZygWe588-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "5ee1ccbe-99de-4d89-d56f-9426e11ab7d4"
      },
      "source": [
        "without_weight_class_result = model.evaluate(val_features, val_targets)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1781/1781 [==============================] - 2s 1ms/step - loss: 0.0227 - fn: 28.0000 - fp: 2.0000 - tn: 56884.0000 - tp: 47.0000 - precision: 0.9592 - recall: 0.6267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ2JpZrf5jgW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "090a199c-f532-4b74-89eb-505ed4d5c259"
      },
      "source": [
        "print(model.metrics_names )\n",
        "print(without_weight_class_result)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'fn', 'fp', 'tn', 'tp', 'precision', 'recall']\n",
            "[0.022713497281074524, 28.0, 2.0, 56884.0, 47.0, 0.9591836929321289, 0.6266666650772095]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdrvoxol5-v6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5d6977c5-2e99-40cd-8430-7c710ea5bac8"
      },
      "source": [
        "print(model.metrics_names )\n",
        "print(with_weight_class_result)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'fn', 'fp', 'tn', 'tp', 'precision', 'recall']\n",
            "[0.07225595414638519, 12.0, 459.0, 56427.0, 63.0, 0.12068965286016464, 0.8399999737739563]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7toplSB82Yk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b6f6bfbf-767b-49f3-9172-c4d486ec8e89"
      },
      "source": [
        "print(model.metrics_names )"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'fn', 'fp', 'tn', 'tp', 'precision', 'recall']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y72ZhDlhwY3v"
      },
      "source": [
        "## Conclusions\n",
        "\n",
        "At the end of training, out of 56,961 validation transactions, we are:\n",
        "\n",
        "- Correctly identifying 66 of them as fraudulent\n",
        "- Missing 9 fraudulent transactions\n",
        "- At the cost of incorrectly flagging 441 legitimate transactions\n",
        "\n",
        "In the real world, one would put an even higher weight on class 1,\n",
        "so as to reflect that False Negatives are more costly than False Positives.\n",
        "\n",
        "Next time your credit card gets  declined in an online purchase -- this is why."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MbsOfM15k6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}